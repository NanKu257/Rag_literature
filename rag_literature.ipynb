{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def ollama_llm(prompt):\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in ollama_llm: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def load_and_parse_pdf(pdf_path):\n",
    "    try:\n",
    "        logging.info(f\"Processing PDF: {pdf_path}\")\n",
    "        loader = UnstructuredPDFLoader(pdf_path, mode=\"elements\", strategy=\"hi_res\")\n",
    "        elements = loader.load()\n",
    "        logging.info(f\"Parsed {len(elements)} elements from the PDF.\")\n",
    "        return elements\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading and parsing PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    return text\n",
    "\n",
    "def extract_content(elements):\n",
    "    try:\n",
    "        text_elements = [el for el in elements if el.metadata['category'] in ['NarrativeText', 'Title']]\n",
    "        table_elements = [el for el in elements if el.metadata['category'] == 'Table']\n",
    "        logging.info(f\"Extracted {len(text_elements)} text elements and {len(table_elements)} table elements.\")\n",
    "        text_content = \"\\n\\n\".join([clean_text(el.page_content) for el in text_elements])\n",
    "        table_content = \"\\n\\n\".join([clean_text(el.page_content) for el in table_elements])\n",
    "        return text_content, table_content\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting content: {e}\")\n",
    "        return \"\", \"\"\n",
    "\n",
    "def create_vectorstore(context):\n",
    "    try:\n",
    "        logging.info(\"Creating embeddings and vector store...\")\n",
    "        embeddings = OllamaEmbeddings(model='mxbai-embed-large')\n",
    "        documents = [Document(page_content=context)]\n",
    "        vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "        logging.info(\"Vector store created.\")\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating vector store: {e}\")\n",
    "        return None\n",
    "\n",
    "def rerank_documents(query, documents, top_k=4):\n",
    "    try:\n",
    "        model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "        doc_embeddings = model.encode([doc.page_content for doc in documents], convert_to_tensor=True)\n",
    "        scores = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
    "        ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, score in ranked_docs[:top_k]]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reranking documents: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Setting\n",
    "\n",
    "Adjust the prompt according to the model you choose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_answer(context):\n",
    "    try:\n",
    "        final_prompt = f\"\"\"\n",
    "        You are an expert in enzyme kinetics. Based on the provided scientific context, extract detailed enzyme kinetics data.\n",
    "        Ensure the data is accurate and strictly follows the specified format.\n",
    "        Do not include any extraneous information. Provide the information in a clear and structured format as specified below.\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Required Format:\n",
    "        Enzyme name: [Enzyme name]\n",
    "        EC Number: [EC Number] OR N/A\n",
    "        Organism: [Organism Name] OR N/A\n",
    "        Substrate: [Substrate Name] OR N/A\n",
    "        Type: [Wild-type OR Mutant (Specify Mutation)]\n",
    "        Protein Identifier: [UniProt ID OR NCBI ID]\n",
    "        Specific Activity: [Value] OR N/A\n",
    "        KM Value: [Value in mM] OR N/A\n",
    "        Kcat Value: [Value per second] OR N/A\n",
    "        kcat/KM: [Value in mM^-1s^-1] OR N/A\n",
    "        pI Value: [Value]\n",
    "        pH Optimum: [Value]\n",
    "        Temperature Optimum: [Value in Celsius]\n",
    "        Molecular Weight: [Value in kDa]\n",
    "        Reaction pH: [Value] OR N/A\n",
    "        Reaction Temperature: [Value in Celsius] OR N/A\n",
    "        Buffer Solution: [Buffer used in the assay]\n",
    "        Activators: [substances that increase activity, or 'N/A']\n",
    "        Inhibitors: [substances that decrease activity, or 'N/A']\n",
    "\n",
    "        Provide only the requested information in the specified format. No additional text or explanations.\n",
    "        \"\"\"\n",
    "        final_answer = ollama_llm(final_prompt)\n",
    "        return final_answer\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating final answer: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_query():\n",
    "    return \"\"\"\n",
    "    Extract detailed enzyme kinetics data including enzyme name, EC number, organism, substrate, type (wild-type or mutant), protein identifier, specific activity, KM value, Kcat value, kcat/KM, pI value, pH optimum, temperature optimum, molecular weight, reaction pH, reaction temperature, buffer solution, activators, and inhibitors.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(pdf_path):\n",
    "    elements = load_and_parse_pdf(pdf_path)\n",
    "    if not elements:\n",
    "        return \"\"\n",
    "    \n",
    "    text_content, table_content = extract_content(elements)\n",
    "    if not text_content and not table_content:\n",
    "        return \"\"\n",
    "\n",
    "    vectorstore = create_vectorstore(text_content + \"\\n\\n\" + table_content)\n",
    "    if not vectorstore:\n",
    "        return \"\"\n",
    "\n",
    "    query = generate_query()\n",
    "    docs = vectorstore.similarity_search(query, k=4) \n",
    "    reranked_docs = rerank_documents(query, docs, top_k=3)\n",
    "    if not reranked_docs:\n",
    "        return \"\"\n",
    "\n",
    "    combined_context = \"\\n\\n\".join([doc.page_content for doc in reranked_docs])\n",
    "    combined_context += \"\\n\\n\" + table_content\n",
    "\n",
    "    logging.info(\"Generating final answer using LLM...\")\n",
    "    final_answer = generate_final_answer(combined_context)\n",
    "    logging.info(\"Final answer generated.\")\n",
    "    \n",
    "    return final_answer\n",
    "\n",
    "def process_folder(folder_path, output_file, log_file, problematic_folder):\n",
    "    if not os.path.exists(problematic_folder):\n",
    "        os.makedirs(problematic_folder)\n",
    "    \n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, \"r\") as f:\n",
    "            processed_files = f.read().splitlines()\n",
    "    else:\n",
    "        processed_files = []\n",
    "    \n",
    "    pdf_paths = [os.path.join(root, file) for root, _, files in os.walk(folder_path) for file in files if file.endswith(\".pdf\")]\n",
    "    \n",
    "    with tqdm(total=len(pdf_paths), unit=\"file\") as pbar:\n",
    "        for pdf_path in pdf_paths:\n",
    "            if pdf_path not in processed_files:\n",
    "                try:\n",
    "                    logging.info(f\"Processing file: {pdf_path}\")\n",
    "                    answer_text = generate_answer(pdf_path)\n",
    "                    if answer_text:\n",
    "                        pmid = os.path.basename(pdf_path).split('_')[0]\n",
    "                        with open(output_file, \"a\") as f:\n",
    "                            f.write(f\"PMID: {pmid}\\n{answer_text}\\n\\n\")\n",
    "                        with open(log_file, \"a\") as f:\n",
    "                            f.write(f\"{pdf_path}\\n\")\n",
    "                    else:\n",
    "                        raise ValueError(\"No answer generated\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {pdf_path}: {e}\")\n",
    "                    with open(\"error_log.txt\", \"a\") as error_log:\n",
    "                        error_log.write(f\"Error processing {pdf_path}: {e}\\n\")\n",
    "                    os.rename(pdf_path, os.path.join(problematic_folder, os.path.basename(pdf_path)))\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the model and folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\")\n",
    "folder_path = \"path/to/pdf/folder/\"\n",
    "output_file = \"output.txt\"\n",
    "log_file = \"processed_log.txt\"\n",
    "problematic_folder = \"problematic_files/\"\n",
    "\n",
    "process_folder(folder_path, output_file, log_file, problematic_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
